Excellent ! Tu veux donc une version o√π :

    Tu as un texte (comme la fiche formation),

    Tu as des m√©tadonn√©es associ√©es (comme ville, diplome, etablissement),

    Tu veux tout stocker proprement avec FAISS, en liant vecteurs ‚Üî m√©tadonn√©es.

FAISS ne stocke que des vecteurs, donc on va garder les m√©tadonn√©es √† part (dans une liste, une base, ou un fichier). Voici un exemple complet :
‚úÖ Exemple avec texte + m√©tadonn√©es

import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

# Simuler quelques fiches avec texte + m√©tadonn√©es
fiches = [
    {
        "text": "Le BUT Informatique de l'IUT de Bordeaux forme des d√©veloppeurs.",
        "metadata": {
            "ville": "Bordeaux",
            "etablissement": "IUT Bordeaux",
            "diplome": "BUT",
            "filiere": "Informatique"
        }
    },
    {
        "text": "Le BTS SIO option SLAM est propos√© au lyc√©e Victor Hugo √† Marseille.",
        "metadata": {
            "ville": "Marseille",
            "etablissement": "Lyc√©e Victor Hugo",
            "diplome": "BTS SIO",
            "filiere": "SLAM"
        }
    },
    {
        "text": "Une licence de biologie est disponible √† l'universit√© de Rennes.",
        "metadata": {
            "ville": "Rennes",
            "etablissement": "Universit√© de Rennes",
            "diplome": "Licence",
            "filiere": "Biologie"
        }
    }
]

# Initialiser le mod√®le d'embedding
model = SentenceTransformer("all-MiniLM-L6-v2")

# Cr√©er les embeddings
texts = [fiche["text"] for fiche in fiches]
embeddings = model.encode(texts).astype("float32")

# Cr√©er l‚Äôindex FAISS
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(embeddings)

# Stocker les m√©tadonn√©es s√©par√©ment (liste parall√®le)
metadata_store = [fiche["metadata"] for fiche in fiches]

# Requ√™te utilisateur
query = "Je cherche une formation en informatique √† Bordeaux"
query_embedding = model.encode([query]).astype("float32")

# Recherche dans FAISS
k = 2
distances, indices = index.search(query_embedding, k)

# Affichage des r√©sultats avec m√©tadonn√©es
print("R√©sultats similaires :")
for i, idx in enumerate(indices[0]):
    print(f"{i+1}. {texts[idx]} (distance: {distances[0][i]:.2f})")
    print("   M√©tadonn√©es :", metadata_store[idx])

‚úÖ R√©sultat attendu (exemple) :

R√©sultats similaires :
1. Le BUT Informatique de l'IUT de Bordeaux forme des d√©veloppeurs. (distance: 0.35)
   M√©tadonn√©es : {'ville': 'Bordeaux', 'etablissement': 'IUT Bordeaux', 'diplome': 'BUT', 'filiere': 'Informatique'}

2. Le BTS SIO option SLAM est propos√© au lyc√©e Victor Hugo √† Marseille. (distance: 0.80)
   M√©tadonn√©es : {'ville': 'Marseille', 'etablissement': 'Lyc√©e Victor Hugo', 'diplome': 'BTS SIO', 'filiere': 'SLAM'}

üß† Ce que tu peux faire ensuite :

    Stocker metadata_store dans un fichier .json

    Sauvegarder l‚Äôindex FAISS :

faiss.write_index(index, "index_faiss.index")

    Cr√©er une fonction de recherche propre (query ‚Üí r√©sultats avec textes + m√©tadonn√©es)

Souhaites-tu qu'on ajoute une fonction de recherche compl√®te avec extraction automatique de filtre plus tard ?